<?xml version="1.0" encoding="utf-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
<!-- 2020-09-22 Tue 11:44 -->
<meta content="text/html;charset=utf-8" http-equiv="Content-Type"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Predicting memory encoding using an OpenBCI</title>
<meta content="Org mode" name="generator"/>
<meta content="lambdaloop" name="author"/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="/css/code-theme.css" rel="stylesheet"/>
<link href="/css/style.css" rel="stylesheet"/>
<script src="/js/footnotes.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div class="status" id="preamble">
<a href="/" id="logo" title="Home">
<img class="logoimg" src="/images/logo_sm.png"/>
    lambdaloop
</a>
<hr/>
</div>
<div id="content">
<h1 class="title">Predicting memory encoding using an OpenBCI</h1>
<div id="text-table-of-contents">
<ul>
<li><a href="#org5b59f40">1. Experiment</a>
<ul>
<li><a href="#orgfb352da">1.1. Start by attaching the OpenBCI electrodes to the participant’s head</a></li>
<li><a href="#org64f2500">1.2. Check connections using the OpenBCI processing sketch</a></li>
<li><a href="#orgc675aaa">1.3. Record positions of EEG according to 10-20 system</a></li>
<li><a href="#orgccc2bf3">1.4. Present list of words and record</a></li>
<li><a href="#org486e7e6">1.5. Test recall</a></li>
</ul>
</li>
<li><a href="#org62040bd">2. Analysis</a></li>
</ul>
</div>
<div class="figure">
<p><img alt="sm_attention_cartoon_zhanna.png" src="/images/eeg-memory/sm_attention_cartoon_zhanna.png" style="max-height: 450px"/>
</p>
</div>
<p>
(Updated image thanks to <a href="https://github.com/zhannar">Zhanna</a>)
</p>
<p>
Two weekends ago, my Neurotech friends and I got together and decided
to replicate an article we saw presented at the <a href="http://bcisociety.org/meetings/bci-meeting-2016-welcome/">BCI conference</a>:
<a href="http://doi.org/10.3217/978-3-85125-467-9-128">Improving Memory Performance Using a Wearable BCI</a> . Since they use an
Emotiv headset, we thought it should be possible to get similar results
(or maybe even better) with an <a href="http://openbci.com/">OpenBCI headset</a>.
</p>
<p>
The basic idea is that when you’re presented with some fact, you may or may not be in the right
state of mind to remember it. At one time, you might be completely focused and be able to recall the
fact precisely at a later time. Many times though, you get distracted (by ice cream or something) and
you have no idea what you read or heard for the last 5 minutes.
</p>
<p>
What if we could automatically detect whether the memory is encoded based on brainwaves at that
time? (It turns out there’s a whole <a href="https://en.wikipedia.org/wiki/Difference_due_to_memory">field</a> about this!) If so, we could improve the flashcard system <a href="http://ankisrs.net/">Anki</a> by showing the cards we think you’ll forget
again earlier.
</p>
<p>
So we did it! We successfully recorded data using the OpenBCI and got some initial results.
</p>
<p>
Making an experiment like this from beginning to end might be daunting, so I’ve documented all our
steps in as much detail as possible.
</p>
<p>
Before we begin, all our code is open-source and you can find it here:
</p>
<p>
<a href="https://github.com/zhannar/anki-eeg">https://github.com/zhannar/anki-eeg</a>
</p>
<p>
Though the README file for the code is decent, I’ll describe the experiment in even more detail below.
</p>
<div class="outline-2" id="outline-container-org5b59f40">
<h2 id="org5b59f40"><span class="section-number-2">1</span> Experiment</h2>
<div class="outline-text-2" id="text-1">
</div>
<div class="outline-3" id="outline-container-orgfb352da">
<h3 id="orgfb352da"><span class="section-number-3">1.1</span> Start by attaching the OpenBCI electrodes to the participant’s head</h3>
<div class="outline-text-3" id="text-1-1">
<p>
<img alt="sm_setup_1.jpg" src="/images/eeg-memory/sm_setup_1.jpg"/>
<img alt="sm_setup_3.jpg" src="/images/eeg-memory/sm_setup_3.jpg"/>
</p>
<p>
Our setup is similar to the <a href="http://docs.openbci.com/tutorials/01-GettingStarted">getting started tutorial</a> from OpenBCI. We also used a combination of <a href="http://www.weaverandcompany.com/ten20.html">Ten20 conductive
paste</a> and cup electrodes, and stuck each on the participant’s scalp. Just as in the tutorial, we
placed the SRB2 reference electrode on one earlobe, and the BIAS reference electrode on the other
earlobe.
</p>
<p>
<img alt="sm_setup_2.jpg" src="/images/eeg-memory/sm_setup_2.jpg"/>
<img alt="sm_setup_4.jpg" src="/images/eeg-memory/sm_setup_4.jpg"/>
</p>
<p>
As can be seen in the images above, the main difference with our setup is that we used all 8
electrodes.  Our reference paper got the strongest results from parietal and occipital regions, so
we placed most of our electrodes there. Most commercial headsets get data primarily from the
prefrontal cortex. We also placed 1-2 electrodes there to cover our bases and hedge against missing
out on potentially useful results.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org64f2500">
<h3 id="org64f2500"><span class="section-number-3">1.2</span> Check connections using the OpenBCI processing sketch</h3>
<div class="outline-text-3" id="text-1-2">
<div class="figure">
<p><img alt="alpha.png" src="/images/eeg-memory/alpha.png" style="max-height: 350px"/>
</p>
</div>
<p>
The OpenBCI tutorial, once again, <a href="http://docs.openbci.com/tutorials/01-GettingStarted#getting-started-w-openbci-ii-downloadrun-the-openbci-gui">walks you through</a> how to get setup and run their processing sketch.
</p>
<p>
To check if you’re getting EEG, we generally look for alpha waves and artifacts (eye blinks and jaw
clench). You can see how those look in the picture above, from the OpenBCI tutorial.
</p>
<p>
If you don’t check the EEG streams before the experiment, you may end up collecting just noise on
some electrodes. In these checks, we often find that 1 or 2 electrodes are loose (possibly including
the reference electrodes!), so we secure them properly.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgc675aaa">
<h3 id="orgc675aaa"><span class="section-number-3">1.3</span> Record positions of EEG according to 10-20 system</h3>
<div class="outline-text-3" id="text-1-3">
<div class="figure">
<p><img alt="sm_10_20.png" src="/images/eeg-memory/sm_10_20.png"/>
</p>
</div>
<p>
We took pictures of the participant’s head after applying the electrodes, then also
recorded where we believed the electrodes were located referencing the 10-20 system diagram
above. Knowing these positions allows us to connect our results back to the neuroscience.
</p>
<p>
In retrospect, a better way to run future experiment would be to standardize the positions first and
then run multiple experiments with the same positions.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgccc2bf3">
<h3 id="orgccc2bf3"><span class="section-number-3">1.4</span> Present list of words and record</h3>
<div class="outline-text-3" id="text-1-4">
<div class="figure">
<p><img alt="sm_experiment.jpg" src="/images/eeg-memory/sm_experiment.jpg"/>
</p>
</div>
<p>
This is where we finally use the code we wrote!
</p>
<p>
You can run this from inside the repo to start the experiment:
</p>
<div class="org-src-container">
<pre class="src src-bash"><span class="org-builtin">cd</span> paradigm
python encode.py
</pre>
</div>
<p>
This will start presenting the words using pygame.  At the same time, it will start collecting EEG
data into data/eeg<sub>TIME.csv</sub> and the words displayed into data/words<sub>TIME.csv</sub>, where TIME is the <a href="https://en.wikipedia.org/wiki/Unix_time">Unix time</a> at the start of recording.
</p>
<p>
After you’ve finished presenting the list of words, you can remove electrodes and unplug the OpenBCI.
</p>
<p>
Wait some time (we tended to wait around 1-5 minutes), then have your subject perform the recall
test.  To keep the experiment controlled, it’s better to have each subject wait the same time
(although we failed to do this in our few runs).
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org486e7e6">
<h3 id="org486e7e6"><span class="section-number-3">1.5</span> Test recall</h3>
<div class="outline-text-3" id="text-1-5">
<div class="figure">
<p><img alt="sm_recognize.png" src="/images/eeg-memory/sm_recognize.png"/>
</p>
</div>
<p>
After the participant has waited for some time, you can initiate the second part of the experiment (testing their recall) by running:
</p>
<div class="org-src-container">
<pre class="src src-bash"><span class="org-builtin">cd</span> paradigm
python recognize.py ../data/words_TIME.csv
</pre>
</div>
<p>
where TIME is the Unix time of your previous recording.
</p>
<p>
This will generate a file in data/words<sub>TIME</sub><sub>labeled.csv</sub>, with an extra column “recognized”,
depending on whether the word was marked as recognized or not by the subject.
</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org62040bd">
<h2 id="org62040bd"><span class="section-number-2">2</span> Analysis</h2>
<div class="outline-text-2" id="text-2">
<p>
You can finally move on to the really interesting part: the analysis!
</p>
<p>
This part is still in progress… We got some interesting results, and I’ll come back and detail them soon…
For now, you can look at our <a href="https://github.com/zhannar/anki-eeg/blob/master/analysis/eeg_analysis.ipynb">mildly documented IPython notebook</a>.
</p>
</div>
</div>
</div>
</body>
</html>
