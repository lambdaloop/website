#+TITLE: Lessons in time management from operating systems

# should rephrase this to have less first person, more approachable writing

When I first read [[https://www.goodreads.com/book/show/25666050-algorithms-to-live-by][Algorithms to Live By]], I was fascinated by the parallels between computer science and cognitive science. At the time, I made a couple of small changes, notably buying a stand for my clothes and making more heavy use of the "recently modified" heuristic when sorting things (or at least, feeling more comfortable with it as reasonably optimal). Three years later, the idea that stuck around is the parallel between scheduling tasks in operating systems and in life.

The book covers scheduling tradeoffs at a pretty high level, focusing primarily on the [[https://en.wikipedia.org/wiki/Earliest_deadline_first_scheduling][earliest deadline first (EDF)]] and [[https://en.wikipedia.org/wiki/Shortest_job_next][shortest job next (SJN)]] algorithms, and has brief discussions on priority inversion and context switching. The book's focus is understandable given the its audience and space constraints, but the recommendations for practical time management feel somewhat shallow (e.g. beware of context switching, check prerequisites for tasks).

Here, I'd like to explore these parallels in more detail, and in the process understand what specific strategies may be learned from the decades of research in operating system scheduling, flavored by what we know about human constraints.


* Parallels between human and OS scheduling

The more that I read about scheduling in operating systems, the more the parallels with human time management become clear. In fact, a lot of the discussion within OS scheduling is rather lucid, and sheds light in the tradeoffs of human time management.

# - context switching / time slices / interrupts
** Context switching: cognitive vs procedural
# Christian and Griffiths make a big deal out of this in /Algorithms to Live By/, and how bad humans are at context switching, something that is covered again and again in the literature.

Looking at OS context switching, we see that there are actually two different costs to context switches, which I distinguish as "procedural" and "cognitive". [fn::In the OS literature, "procedural" and "cognitive" costs are generally referred to as "direct" and "indirect" costs.] When switching tasks in a CPU, the biggest task is just switching out the values of the registers. This would be a "procedural" cost. However, as a CPU executes, it builds up state in various caches, which must be refilled again when switching tasks. This cost, much harder to quantify, would be a "cognitive" cost.

For humans, a "procedural" cost of switching tasks involves the physical setup of a task (opening a document on the computer, setting a brushes for painting, etc), whereas the "cognitive" cost is due to switching out the working memory maintained while working on a task (e.g. what sentence to write next, in which region to paint). The human task-switching literature has focused primarily on quantifying the cognitive cost of task switching. However, this cost may in fact be irrelevant if the procedural cost is high enough. Interestingly, for operating systems, it may also be negligible for simple tasks where both tasks fit in cache. It's possible that there are tasks simple enough that they incur almost no cognitive cost for humans as well.


** Time to completion: often unknown
Something that I find really interesting in the OS literature, which is completely glossed over in /Algorithms to Live By/, is that most of modern scheduling algorithms don't make any assumptions about the length of each task when scheduling them. People are notoriously bad at estimating tasks[fn:students-paper], so having a system which can process multiple tasks of arbitrary lengths robustly seems rather interesting. In both of the modern schedulers described below, the scheduler is designed to handle a mix of long and short running tasks with minimal sacrifices on the run time of either.

[fn:students-paper] For instance, the majority of students underestimated how long it would take to finish a paper by about 50% when optimistic, and even by 12% when asked to make a pessimistic estimate.  (Buehler, Griffin, Ross, 1994)

** Turnaround time vs response time: choose one

# add picture from the scheduling book here to demonstrate difference between SJF and Round Robit (Figures 7.6 and 7.7)
A natural metric to optimize for completing tasks is the "turnaround time", defined as the time from task arrival to task completion. However, engineers of interactive systems quickly realized that considering only turnaround time leads to laggy and unresponsive interfaces. This is because, optimizing for turnaround time, the system would just run one task at time, for a long time. Thus, from the perspective of the user, their task would usually freeze up
until all the other shorter tasks completed.

The solution is to measure and optimize the response time, the time from the task arrival to the first task run. I find this interesting, as in our modern social networks we are often incentivized to minimize response time, rather than turnaround time, which naturally leads to us performing tasks in [[https://en.wikipedia.org/wiki/Round-robin_scheduling][round-robin]] style.  Rather than holding turnaround time as the best metric and completely discounting round-robin scheduling, as so many "productivity gurus" often do, it can be helpful to think about the balance between response time and turnaround time, and what you might be trading off when picking one to optimize.

** Input/output: blocks tasks
# visualization of this

Another consideration when scheduling tasks is the waiting time for input/output. For instance, when the CPU is reading from or writing to a hard drive, it must wait for the hard drive to respond before continuing to execute the task, as hard drives are orders of magnitude slower than CPUs. But it could be executing other tasks during this time!

A similar principle applies for human tasks. When running the laundry, for instance, it's more efficient to not wait for the washer to finish before starting another task. Similarly, when waiting for a reply to a message or waiting for water to boil, it's more efficient be doing something else. You can think of delegating tasks to people or machines in this way as well. Still, how can you schedule tasks most efficiently while keeping this in mind? The modern algorithms below handle these issues naturally.

* Modern schedulers
** Multi-level feedback queue
- optimizes turnaround time
- multiple queues, take advantage of past knowledge
  
** Fair-share scheduler
- optimizes fair CPU usage
- prioritizes response time (?)
- CFS part of linux

* Multitasking: a human perspective
- multiprocessing can happen, but it has to be split across domains
  + for instance, doing a visuomotor task but listening to audio is pretty common
  + similarly, having a conversation is possible while watching things
  + sensorimotor task (e.g. sewing) and watching a show
  + walking and chewing gum
- supertaskers

- delegating tasks within a team
  + multiple queues?


* Summary of lessons learned

